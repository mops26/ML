# üìö ML –ú–æ–¥—É–ª—å: Student-Themes Matching Model

üéØ –ß—Ç–æ —ç—Ç–æ?
ML –º–æ–¥–µ–ª—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫ —É—á–µ–±–Ω—ã–º/–Ω–∞—É—á–Ω—ã–º —Ç–µ–º–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ:

- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–æ–≤ (Sentence Transformers)

- –°–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–π (–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Üí Machine Learning)

- –°–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤ (Python, Docker, React –∏ —Ç.–¥.)

- –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–∏ (—á–∞—Å–æ–≤ –≤ –Ω–µ–¥–µ–ª—é)

## 1. **–£—Å—Ç–∞–Ω–æ–≤–∫–∞**

–®–∞–≥ 1: –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ –ø—Ä–æ–µ–∫—Ç

–°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π

`git clone https://github.com/Netnol/Students_To_Themes.git`
–ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –ø–∞–ø–∫—É —Å ML –º–æ–¥–µ–ª—å—é

`cd Students_To_Themes/ML`

–®–∞–≥ 2: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

`pip install -r requirements.txt`

## 2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –ø–∞–ø–∫–∞ tests/

`python -m pytest tests/`

–ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–µ—Å—Ç

`python tests/test_normalization.py`
`python tests/test_skills.py`

## 3. –ö–∞–∫ –º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å

### 3.1 –°–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤

–í —Ñ–∞–π–ª–µ main.py –∏–∑–º–µ–Ω–∏—Ç–µ —Å—Ç—Ä–æ–∫—É 20:

–ë—ã–ª–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é):

`def __init__(self, model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'):`

–°—Ç–∞–ª–æ (–±–æ–ª–µ–µ –ª–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å):

`def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):`

–ò–ª–∏ –±–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å:

`def __init__(self, model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2'):`

–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:

- all-MiniLM-L6-v2 - –º–∞–ª–µ–Ω—å–∫–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)

- paraphrase-multilingual-MiniLM-L12-v2 - —Å—Ä–µ–¥–Ω—è—è, –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)

- paraphrase-multilingual-mpnet-base-v2 - –±–æ–ª—å—à–∞—è –∏ —Ç–æ—á–Ω–∞—è

### 3.2 –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
–í —Ñ–∞–π–ª–µ main.py –Ω–∞–π–¥–∏—Ç–µ —Å–ª–æ–≤–∞—Ä—å specialization_mapping (—Å—Ç—Ä–æ–∫–∏ 22-35)

–î–æ–±–∞–≤—å—Ç–µ –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å:

`self.specialization_mapping['–ù–µ–π—Ä–æ–±–∏–æ–ª–æ–≥–∏—è'] = [
    '–ù–µ–π—Ä–æ–±–∏–æ–ª–æ–≥–∏—è',
    '–Ω–µ–π—Ä–æ–±–∏–æ–ª–æ–≥–∏—è', 
    'neuroscience',
    'brain research'
]
`
–ò –¥–æ–±–∞–≤—å—Ç–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è–º–∏ (—Å—Ç—Ä–æ–∫–∞ ~98):

`related_specs['–ù–µ–π—Ä–æ–±–∏–æ–ª–æ–≥–∏—è'] = ['Machine Learning', 'Data Science']`
### 3.3 –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π –Ω–∞–≤—ã–∫
–í —Ñ–∞–π–ª–µ main.py –Ω–∞–π–¥–∏—Ç–µ —Å–ª–æ–≤–∞—Ä—å skill_keywords (—Å—Ç—Ä–æ–∫–∏ 58-94)

–î–æ–±–∞–≤—å—Ç–µ –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å:

`skill_keywords['bioinformatics'] = [
    '–±–∏–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞',
    'bioinformatics',
    '–≥–µ–Ω–æ–º–∏–∫–∞',
    'genomics',
    '–î–ù–ö',
    'DNA'
]`
### 3.4 –ò–∑–º–µ–Ω–∏—Ç—å –≤–µ—Å–∞ –æ—Ü–µ–Ω–∫–∏
–í —Ñ–∞–π–ª–µ main.py –Ω–∞–π–¥–∏—Ç–µ –º–µ—Ç–æ–¥ calculate_comprehensive_score (—Å—Ç—Ä–æ–∫–∞ 129)

–ò–∑–º–µ–Ω–∏—Ç–µ –≤–µ—Å–∞:

–ë—ã–ª–æ:

`weights = {'semantic': 0.4, 'specialization': 0.3, 'skills': 0.2, 'hours': 0.1}`

–°—Ç–∞–ª–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –±–æ–ª—å—à–µ –≤–Ω–∏–º–∞–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏–∫–µ):

`weights = {'semantic': 0.5, 'specialization': 0.25, 'skills': 0.15, 'hours': 0.1}`
### 3.5 –°–æ–∑–¥–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—É—é –º–æ–¥–µ–ª—å

`from main import CSVStudentTopicMatcher

class CustomStudentMatcher(CSVStudentTopicMatcher):
    """–ö–∞—Å—Ç–æ–º–Ω–∞—è –º–æ–¥–µ–ª—å —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏"""
    
    def __init__(self):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å
        super().__init__(model_name='sentence-transformers/all-MiniLM-L6-v2')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self.specialization_mapping['–ì–µ–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞'] = [
            '–ì–µ–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞',
            '–≥–µ–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞',
            'GIS',
            'geoinformatics'
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏
        self.skill_keywords['gis'] = [
            'arcgis',
            'qgis',
            '–≥–µ–æ–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã',
            '–∫–∞—Ä—Ç–æ–≥—Ä–∞—Ñ–∏—è'
        ]
    
    def calculate_comprehensive_score(self, semantic_similarity, spec_match, 
                                    skill_match, hours_score, weights=None):
        """–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Å–∞ –æ—Ü–µ–Ω–∫–∏"""
        custom_weights = {
            'semantic': 0.45,      # –ë–æ–ª—å—à–µ –≤–Ω–∏–º–∞–Ω–∏—è —Å–º—ã—Å–ª—É
            'specialization': 0.3,  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ
            'skills': 0.15,         # –ú–µ–Ω—å—à–µ –≤–Ω–∏–º–∞–Ω–∏—è –Ω–∞–≤—ã–∫–∞–º
            'hours': 0.1           # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ
        }
        return super().calculate_comprehensive_score(
            semantic_similarity, spec_match, skill_match, hours_score, custom_weights
        )
    
    def get_detailed_scores(self, students_data, theme_data, target_specialization):
        """–ù–æ–≤—ã–π –º–µ—Ç–æ–¥: –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É, –Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        students_df = self.preprocess_student_data(students_data)
        processed_theme = self.preprocess_theme_data(theme_data)
        
         ...
        return detailed_results`

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

custom_matcher = CustomStudentMatcher()

## 4. –û–±—É—á–µ–Ω–∏–µ

–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:
- –ï—Å–ª–∏ –≤–∞–º –Ω—É–∂–Ω–æ –æ–±—É—á–µ–Ω–∏–µ, –Ω–∞—á–Ω–∏—Ç–µ —Å —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:

- –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ–∫—É—â—É—é —Å–∏—Å—Ç–µ–º—É

- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–¥–±–æ—Ä–∞

- –û—Ç–º–µ—á–∞–π—Ç–µ, –∫–∞–∫–∏–µ –ø–æ–¥–±–æ—Ä—ã –±—ã–ª–∏ —Ö–æ—Ä–æ—à–∏–º–∏/–ø–ª–æ—Ö–∏–º–∏

- –ü–æ—Å–ª–µ —Å–±–æ—Ä–∞ 100-200 –ø—Ä–∏–º–µ—Ä–æ–≤ - –¥–æ–±–∞–≤–∏–º –ø—Ä–æ—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ

training.py

